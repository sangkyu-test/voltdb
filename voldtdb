[MASTER NODE]
vi /etc/hosts
172.16.0.214	kuber1m
172.16.1.55	kuber1n
172.16.1.31	kuber3n
172.16.3.80	kuber4n

setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
init 6

systemctl stop firewalld && systemctl disable firewalld && systemctl mask --now firewalld

cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sysctl --system

swapoff -a
/etc/fstab 파일의 swap부분 주석처리
#/dev/mapper/centos-swap swap                    swap    defaults        0 0

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

yum install kubeadm docker -y
systemctl enable kubelet && systemctl start kubelet 
systemctl enable docker && systemctl start docker

kubeadm init

kubeadm join 172.16.0.214:6443 --token hg5vlq.af1kg0od698goe3u --discovery-token-ca-cert-hash sha256:2e2d23510d0ca466bbed8d7e0f600cccd12be2adc9ef8e58cc933aeca24cad03

mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

[root@kuber1m ~]# kubectl get nodes
NAME      STATUS     ROLES    AGE   VERSION
kuber1m   NotReady   master   50s   v1.17.3

export kubever=$(kubectl version | base64 | tr -d '\n')
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$kubever"

클러스터 생성이후 master가 NotReady -> Ready 로 변경됨을 확인할 수 있다.
[root@kuber1m ~]# kubectl get nodes
NAME      STATUS   ROLES    AGE     VERSION
kuber1m   Ready    master   3m25s   v1.17.3

======================================================================================================================
[WORKER NODE]
vi /etc/hosts
172.16.0.214	kuber1m
172.16.1.55	kuber1n
172.16.1.31	kuber3n
172.16.3.80	kuber4n

setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
init 6

systemctl stop firewalld && systemctl disable firewalld && systemctl mask --now firewalld

swapoff -a
/etc/fstab 파일의 swap부분 주석처리
#/dev/mapper/centos-swap swap                    swap    defaults        0 0

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

yum install kubeadm docker -y 
systemctl enable kubelet && systemctl start kubelet
systemctl enable docker && systemctl start docker

kubeadm join 172.16.0.214:6443 --token hg5vlq.af1kg0od698goe3u --discovery-token-ca-cert-hash sha256:2e2d23510d0ca466bbed8d7e0f600cccd12be2adc9ef8e58cc933aeca24cad03

===============================================================================================================================
[Master node NFS Server install]
yum install nfs-utils nfs-utils-lib
systemctl enable nfs-server.service
systemctl start nfs-server.service

vi /etc/exports
/srv/nfs/kubedata *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)
exportfs -rav
exportfs -v

mkdir /srv/nfs/kubedata -p
chown nobody: /srv/nfs/kubedata

[worker node NFS client install]
yum install nfs-utils nfs-utils-lib -y 
systemctl enable nfs-client.target
systemctl start nfs-client.target

worker node에서 master node로 NFS 정상적으로 연결되는지 확인
mount -t nfs 192.168.11.102:/srv/nfs/kubedata /tmp

==========================================================================================================
[Master node ]
kubectl get clusterrole,clusterrolebinding,role,rolebinding | grep nfs

kubectl create -f rbac.yaml

[root@kuber1m yaml]# kubectl get clusterrole,clusterrolebinding,role,rolebinding | grep nfs
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner                                          4s
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner                             4s
role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner   4s
rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner   4s

kubectl create -f class.yaml
storageClass 설정

kubectl create -f deployment.yaml
nfs-server의 IP를 지정해주고 마운트위치를 지정해주면 된다.

그리고  storageClass를 지정해서 pvc를 생성해서 할당요청을 하면 할당을 자동으로 해준다.
kubectl create -f pvc-nfs.yaml

PVC를 이용해 pod를 생성하면 pv,pvc를 기준으로 올라간다.(미리 생성해둔 pv,pvc가 있다.)
kubectl create -f 4-busybox-pv-hostpath.yaml

pod(pvc)를 포함한 yaml 파일로 pod를 올릴 때  pvc에 지정한 storageClassName으로 할당을 자동으로 할 수 있다.

나중에 worker node를 추가할려면 해당 토큰이 24시간밖에 유효하지 않기 때문에 재 생성해서 노드를 추가해줘야 한다.
마스터에서 kubeadm token create --print-join-command
kubeadm join 192.168.11.102:6443 --token 6pdmn3.pemj5ff2smoqtktm     --discovery-token-ca-cert-hash sha256:2e2d23510d0ca466bbed8d7e0f600cccd12be2adc9ef8e58cc933aeca24cad03

cd
bash voltdb-k8s-utils.sh config.cfg -B
bash voltdb-k8s-utils.sh config.cfg -M
bash voltdb-k8s-utils.sh config.cfg -C
bash voltdb-k8s-utils.sh config.cfg -S
