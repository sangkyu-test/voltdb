[Kubernetes MASTER NODE 환경 구성]
vi /etc/hosts
172.16.0.214	kuber1m
172.16.1.55	kuber1n
172.16.1.31	kuber3n
172.16.3.80	kuber4n

setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
init 6

systemctl stop firewalld && systemctl disable firewalld && systemctl mask --now firewalld

cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sysctl --system

swapoff -a
/etc/fstab 파일의 swap부분 주석처리
#/dev/mapper/centos-swap swap                    swap    defaults        0 0

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

yum install kubeadm docker -y
systemctl enable kubelet && systemctl start kubelet 
systemctl enable docker && systemctl start docker

kubeadm init

kubeadm join 172.16.0.214:6443 --token hg5vlq.af1kg0od698goe3u --discovery-token-ca-cert-hash sha256:2e2d23510d0ca466bbed8d7e0f600cccd12be2adc9ef8e58cc933aeca24cad03

mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

[root@kuber1m ~]# kubectl get nodes
NAME      STATUS     ROLES    AGE   VERSION
kuber1m   NotReady   master   50s   v1.17.3

export kubever=$(kubectl version | base64 | tr -d '\n')
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$kubever"

클러스터 생성이후 master가 NotReady -> Ready 로 변경됨을 확인할 수 있다.
[root@kuber1m ~]# kubectl get nodes
NAME      STATUS   ROLES    AGE     VERSION
kuber1m   Ready    master   3m25s   v1.17.3

======================================================================================================================
[Kubernetes WORKER NODE 환경 구성]
vi /etc/hosts
172.16.0.214	kuber1m
172.16.1.55	kuber1n
172.16.1.31	kuber3n
172.16.3.80	kuber4n

setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
init 6

systemctl stop firewalld && systemctl disable firewalld && systemctl mask --now firewalld

swapoff -a
/etc/fstab 파일의 swap부분 주석처리
#/dev/mapper/centos-swap swap                    swap    defaults        0 0

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

yum install kubeadm docker -y 
systemctl enable kubelet && systemctl start kubelet
systemctl enable docker && systemctl start docker

kubeadm join 172.16.0.214:6443 --token hg5vlq.af1kg0od698goe3u --discovery-token-ca-cert-hash sha256:2e2d23510d0ca466bbed8d7e0f600cccd12be2adc9ef8e58cc933aeca24cad03

여기에 노드 정상적으로 Reday상태인걸 복사해서 보여주자!
kubectl cluster-info 결과값도
===============================================================================================================================
[Master node NFS Server install]
yum install nfs-utils nfs-utils-lib
systemctl enable nfs-server.service
systemctl start nfs-server.service

vi /etc/exports
/srv/nfs/kubedata *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)
exportfs -rav
exportfs -v

mkdir /srv/nfs/kubedata -p
chown nobody: /srv/nfs/kubedata

[worker node NFS client install]
yum install nfs-utils nfs-utils-lib -y 
systemctl enable nfs-client.target
systemctl start nfs-client.target

worker node에서 master node로 NFS 정상적으로 연결되는지 확인
mount -t nfs 192.168.11.102:/srv/nfs/kubedata /tmp

==========================================================================================================
[Master node ]
kubectl get clusterrole,clusterrolebinding,role,rolebinding | grep nfs

kubectl create -f rbac.yaml
여기에 야물파일 다운로드 받을 수 있는 git 저장소의 위치를 지정해주자!

[root@kuber1m yaml]# kubectl get clusterrole,clusterrolebinding,role,rolebinding | grep nfs
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner                                          4s
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner                             4s
role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner   4s
rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner   4s

여기에 야물파일 다운로드 받을 수 있는 git 저장소의 위치를 지정해주자!
kubectl create -f class.yaml
storageClass 설정

kubectl create -f deployment.yaml
nfs-server의 IP를 지정해주고 마운트위치를 지정해주면 된다.

그리고  storageClass를 지정해서 pvc를 생성해서 할당요청을 하면 할당을 자동으로 해준다.
kubectl create -f pvc-nfs.yaml

PVC를 이용해 pod를 생성하면 pv,pvc를 기준으로 올라간다.(미리 생성해둔 pv,pvc가 있다.)
kubectl create -f 4-busybox-pv-hostpath.yaml

pod(pvc)를 포함한 yaml 파일로 pod를 올릴 때  pvc에 지정한 storageClassName으로 할당을 자동으로 할 수 있다.

나중에 worker node를 추가할려면 해당 토큰이 24시간밖에 유효하지 않기 때문에 재 생성해서 노드를 추가해줘야 한다.
마스터에서 kubeadm token create --print-join-command
kubeadm join 192.168.11.102:6443 --token 6pdmn3.pemj5ff2smoqtktm     --discovery-token-ca-cert-hash sha256:2e2d23510d0ca466bbed8d7e0f600cccd12be2adc9ef8e58cc933aeca24cad03

나중에 worker node를 추가할려면 해당 토큰이 24시간밖에 유효하지 않기 때문에 재 생성해서 노드를 추가해줘야 한다.
마스터에서 kubeadm token create --print-join-command

[VOLTDB]
다운로드 및 구성 순서
https://www.voltdb.com/ 오른쪽 상단의 DOWNLOAD 버튼을 틀릭하면 개인정보를 넣는 부분이 나오면 작성을 하고 저장하면
개인정보에 작성한 메일주소로 voltdb를 다운받을 수 있는 URL를 보내준다. 해당 URL클릭해서 다운로드 하면 된다.

cd /opt/
tar -zxvf voltdb-ent-9.2.2.tar.gz
cd voltdb-ent-9.2.2/tools/kubernetes/

bash voltdb-k8s-utils.sh config_template.cfg -B
bash voltdb-k8s-utils.sh config_template.cfg -M
bash voltdb-k8s-utils.sh config_template.cfg -C
bash voltdb-k8s-utils.sh config_template.cfg -S

처음에 아래와 같이 설정하지 않은 상태에서 -B 옵션으로 build하게 되면 CLUSTER_NAME이 지정이 되어 있지 않다고 에러 발생한다.
build하기 위해선 CLUSTER_NAME 지정을 해준 상태에서 진행해야 된다.
export CLUSTER_NAME="voltdb"

-C 옵션으로 yaml 파일을 생성하면 CLUSTER_NAME으로 생성이 된다.
voltdb.yaml
해당 yaml 파일을 생성할 때 voltdb-statefulset.yaml 파일을 기준으로 생성을 하게된다.
여기에서 주의할 점은 volumeClaimTemplates 의 하위에 storageClassName: <managed-nfs-storage>
volumeClaimTemplates:
- metadata:
    name: voltdbroot
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: --pvolumeSize--
    storageClassName: managed-nfs-storage <--- 해당부분에 storageClassName을 추가 해줘야 한다.







[구동테스트]
1. 구동테스트를 실행할 컨테이너에 접속해서 스키마 로딩 
kubectl exec -it <pod hostname> -- bash
cd voltdb-ent-9.2.2/examples/voter
../../bin/sqlcmd --servers=<pod hostname> < ddl.sql

2. run.sh에서 수정이 필요한 부분(--servers=<pod name>)
vi run.sh
...
function async-benchmark() {
    jars-ifneeded
    java -classpath voter-client.jar:$CLIENTCLASSPATH voter.AsyncBenchmark \
        --displayinterval=5 \
        --warmup=5 \
        --duration=120 \
        --servers=<voltdb-0,voltdb-1,voltdb-2> \       
        --contestants=6 \
        --maxvotes=2
}
...
3. web 실행명령어
./run.sh webserver

4. 어플리케이션 실행 명령어
./run.sh client

5. web접속을 위한 voltdb 컨테이너와의 터널링 설정
   - localhost <-> 컨테이너 아이피
   - localhost:8081
   

bash voltdb-k8s-utils.sh config.cfg -B
bash voltdb-k8s-utils.sh config.cfg -M
bash voltdb-k8s-utils.sh config.cfg -C
bash voltdb-k8s-utils.sh config.cfg -S
